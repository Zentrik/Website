---
title: Pontryagin's minimum principle
summary: A brief summary of the proof of pontryagin's minimum principle and explanation of $\lambda_0$
author:
- admin
tags: []
categories: []
date: "2021-06-27T17:00:45.785Z" #"2021-06-27T17:00:45.785Z"
lastMod: "2021-06-27T17:00:45.785Z"
featured: false
draft: true

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
image:
  caption: ""
  focal_point: ""

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references 
#   `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []

output:
  blogdown::html_page:
    toc: true
bibliography: ref.bib
---

Pontryagin’s principle is a set of necessary conditions for an optimal solution to a dynamical system.

The general problem is stated as 
\begin{align*}
  \min K(t_0, x(t_0), t_f, x(t_f)) + \int_{t_0}^{t_f} L(x, u, t) \\
  \text{s.t. } \dot{x} = f(x, u, t),\ (t_0, x(t_0), t_f, x(t_f)) \in \mathcal{B},\ u \in U
\end{align*}

This in the form of a bolza problem @bolza and can be converted to a Mayer problem, where $L \equiv 0$, or a Lagrange problem, where $K \equiv 0$ quite easily (see @bolza or @lib2012).

The time dependence in the dynamics and the cost can also be easily incorporated into the state by augmenting the state with a variable representing time.

This reformulated problem is stated as the following, where $x$ is the augmented state and $L$ the augmented cost
\begin{align*}
  \min &\int_{t_0}^{t_f} L(x, u) \\
  \text{s.t. } \dot{x} = f(x, u)&,\ (x(t_0), x(t_f)) \in \mathcal{B},\ u \in U
\end{align*} 

Pontryagin’s principle for this problem is as follows. Let $x(t),\ u(t),\ \lambda_0,\ \lambda(t),\ t_0,\ t_f$ be the optimal solutions to the problem.

(i) There exist an absolutely continuous function $\hat{\lambda}(t) = (\lambda_0, \lambda(t))$ defined on $[t_0, t_f]$ such that $\lambda_0$ is either identically minus one or zero, and $\hat{\lambda} \neq \boldsymbol 0$ for all $t \in [t_0, t_f]$

(ii)
\begin{align*}
  \dot{\lambda} = -\frac{\partial H}{\partial x} \left( x(t),\ u(t),\ \lambda_0,\ \lambda \right)
\end{align*} 

(iii)
\begin{align*}
  H(x(t),\ u(t),\ \hat{\lambda}(t)) \geq H(x(t),\ w,\ \hat{\lambda}(t)) \hspace{0.3cm} \; \forall \; w \in \Psi \hspace{0.3cm} \text{a.e. on } t \in [t_0, t^*_f]
\end{align*} 
Simply put the Hamiltonian must be maximised with respect to $u$ at all times.

(iiii)
The following *transversality condition* must be satisfied: Let $\psi(t) = [x^T(t), u^T(t), \hat{\lambda}^{T}(t) ]^{T}$, then $[ H(\psi(t_0)),\ -\lambda(t_0)^T,\ -H(\psi(t_f)),\ \lambda(t_f)^T ]^T$ must be orthogonal to $\mathcal{B}$ at the point $[ t_0,\ x^T(t_0),\ t^*_f,\ x^T(t_f) ]$.
The Hamiltonian at initial time is 0 if we can vary the initial time and same for final time?
Cite

There are many different proofs for Pontryagin’s principle depending on how formal we want to be and if we have initial/ target sets etc ...

# Dynamic Programming

There is the dynamic programming approach in @ber2017 or @lib2012

# Simple Problem
Fixed time?
Let's say our problem is 
\begin{align*}
  \max \Psi(x(T)) \\
  \text{s.t. } \dot{x} = f(x, u), \ u \in U
\end{align*}

If we have trajectories $(x_\epsilon, u_\epsilon)$ which are a variation of the optimal trajectories $(x^*, u^*)$ with $\epsilon \geq 0$ and \begin{align*}
  \lim_{\epsilon \to 0^+} (x_\epsilon, u_\epsilon) = (x^*, u^*)
\end{align*} 
Now, we know a small increase in $\epsilon$ at $\epsilon=0$ must decrease the objective function. Therefore
\begin{align*}
  0 \geq \left. \frac{\partial}{\partial \epsilon} \right|_{\epsilon=0^+} \Psi(x_\epsilon(T)) = \nabla \Psi(x^*(T)) \left. \frac{\partial}{\partial \epsilon} \right|_{\epsilon=0^+} x_\epsilon(T)
\end{align*} 
Let $p(T) = \nabla \Psi(x^*(T))$ and $v(T) = \left. \frac{\partial}{\partial \epsilon} \right|_{\epsilon=0^+} x_\epsilon(T)$. So $p(T) v(T) \leq 0$

We want to show $p(t)f(x^*, u^*) \leq p(t)f(x^*, u)$ for all $u \in U$ and $t \in [0, T]$. If we construct $v(T) = f(x^*, u^*) - f(x^*, u)$ then we have show the statement to be true when $t = T$. Additionally if we can show $p(t)v(t)$ has the same sign for all $t \in [0, T]$ then we have proved the statement.

We want a variation that is small but big ...
It turns out we can use a type of variation called a needle variation which is 
\begin{align*}
  u_\epsilon(t) = \begin{cases}
    \omega & \text{if } t \in [\tau - \epsilon, \tau] \\
    u^*(t) & \text{else}
  \end{cases} 
\end{align*} 
where $\tau \in (0, T]$ and $0 < \tau - \epsilon < \tau$ and $\omega \in U$.

Let $x_\epsilon(t)$ be the corresponding response to our system:
\begin{align*}
  \dot{x}_\epsilon(t) &= f(x_\epsilon(t), u_\epsilon(t)) \\
  x_\epsilon(0) &= x^0.
\end{align*}

We want to understand how our choices of $\tau$ and $\omega$ cause $x_\epsilon(t)$ to differ from $x^*(t)$ for small $\epsilon > 0$.

Clearly $x_\epsilon(t) = x^*(t)$ for $0 \leq t \leq \tau - \epsilon$. We also get $x_\epsilon(\tau) - x^*(\tau) = (f(x^*(\tau), \omega) - f(x^*(\tau), u^*(\tau))) \epsilon$ from @aro123.

We can find $x_\epsilon(\tau) = x^*(\tau) + \epsilon y + o(\epsilon)$, where $y = f(x^*(\tau), \omega) - f(x^*(\tau), u^*(\tau))$, and then for $t \geq \tau$ both $x^*(t)$ and $x_\epsilon(t)$ follow $u^*(t)$ so they solve the same ODE but with differing initial conditions.

We want $v(t) = \left. \frac{\partial}{\partial \epsilon} \right|_{\epsilon=0^+} x_\epsilon(t)$ (why?).
Let $c(t) = \left. \frac{\partial}{\partial \epsilon} \right|_{\epsilon=0^+} x_\epsilon(t)$ for clarity.

We can use a Maclaurin series to see the following:
\begin{align*}
  x_\epsilon(t) &= x^*(t) + \epsilon c(t) + o(\epsilon) \\
  \text{So } c(\tau) &= y
\end{align*} 
So let $v(\tau) = y$.
Also,
\begin{align*}
  \dot{x}_\epsilon(t) &= \dot{x}^*(t) + \epsilon c(t) \text{ for } t \geq \tau \\
  \dot{x}_\epsilon(t) &= f(x_\epsilon(t), u^*(t)) \text{ for } t \geq \tau  \\
  &= f(x^*(t) + \epsilon c(t) + o(\epsilon), u^*(t)) \\
  &\approx f(x^*(t), u^*(t)) + \epsilon c(t) \nabla_x f(x^*(t), u^*(t)) \\
  &= \dot{x}^*(t) + \epsilon c(t) \nabla_x f(x^*(t), u^*(t)) \\
  \therefore \dot{c}(t) &= \nabla_x f(x^*(t), u^*(t))
\end{align*} 
Therefore, we let $\dot{v}(t) = \nabla_x f(x^*(t), u^*(t))$.
And so $v(t) = c(t)$ for $t \geq \tau$. 
We let $v(t) = 0$ for $0 \leq t < \tau$.

We can construct $p(t)$ so that $p(t)v(t)$ as the same sign for all $t \in [0, T]$ by setting $\frac{d }{d t} p(t)v(t) = 0$. This gives us $\dot{p}(t) = - \nabla_x f(x^*(t), u^*(t)) p(t)$. 

So now we know $p(t)v(t) \leq 0 $ for all $t$.
Now to finish the proof we can note that $v(\tau) = f(x^*(\tau), \omega) - f(x^*(\tau), u^*(\tau))$ a.e. on $\tau \in (0, T)$ for all $\omega \in U$.
This completes the proof.

Free time set final time to 1 and add time dilation factor, $s$, to $x$ then everything same but $\hat{H} = H + p_{n + 1}$ so $\hat{H} = 0$?

You may want to look at A.2 and A.3 in https://math.berkeley.edu/~evans/control.course.pdf, @aro23, @aro123 and 4.2.3 and 4.2.4 from @lib2012.

# Original Proof
@lib2012

The book has a good summary so I'm not going to discuss this proof in much detail. It differs from the previous one as it has a set in which the final state and it deals with $u \in U$ better?

Slides from a talk I gave trying to summarise this proof.

# On manifolds

See @lib2012, I don't have anything to add.

# Role of abnormal multiplier $\lambda_0$

$\lambda_0$ = 0 is an abnormal problem, implying the system is not controllable/ the normality condition is not satisfied/ fixed time, but non fixed final state will never be abnormal? 

For linear control systems All  trajectories  for  uncontrollable  systems  are  possibly  abnormal  extremals \dots

The separating hyperplane must be vertical for $\lambda_0 = 0$. We require $\lambda_0 = 0$, i.e. it can't be $-1$, if and only if $(-1, 0)$ lies on the boundary of the tangent cone.

If an extremal trajectory is not tangent to $S_1$ then $\lambda^0 \neq 0$.
Consider the tangent space to $S_1$ and the line formed by variations to the final time, both lines lie in the hyperplane due to separating hyperplane theorem \dots
The line formed by variations to the final time will be tangent to trajectory at optimal final time as the line is just the gradient of $f$ at final time.
The hyperplane is vertical iff the tangent space and line are coincident hopefully clear geometrically but proof \dots
So $\lambda^0 = 0$ iff "

I have not seen a proof of this or even a statement with the iff so not sure if it really is true but it does seem true doesn't it.

### Nonlinear Optimal Control Theory by Leonard David Berkovitz, Negash G. Medhin

The sequel to citation 23 in the paper

# References