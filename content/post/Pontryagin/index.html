---
title: Pontryagin's minimum principle
summary: A brief summary of the proof of pontryagin's minimum principle and explanation of $\lambda_0$
author:
- admin
tags: []
categories: []
date: "2021-06-27T17:00:45.785Z" #"2021-06-27T17:00:45.785Z"
lastMod: "2022-03-02"
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
image:
  caption: ""
  focal_point: ""

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references 
#   `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []

output:
  blogdown::html_page:
    toc: true
bibliography: ref.bib
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>

<div id="TOC">
<ul>
<li><a href="#statement-of-pontryagins-principle">Statement of Pontryagin’s principle</a></li>
<li><a href="#proofs">Proofs</a>
<ul>
<li><a href="#dynamic-programming">Dynamic Programming</a></li>
<li><a href="#quick-proof">Quick Proof</a></li>
<li><a href="#original-proof">Original Proof</a></li>
</ul></li>
<li><a href="#role-of-abnormal-multiplier-lambda_0">Role of abnormal multiplier <span class="math inline">\(\lambda_0\)</span></a></li>
<li><a href="#references">References</a></li>
</ul>
</div>

<div id="statement-of-pontryagins-principle" class="section level1">
<h1>Statement of Pontryagin’s principle</h1>
<p>Consider the Bolza problem (<span class="citation"><a href="#ref-bolza" role="doc-biblioref"><span>“Bolza Problem - Encyclopedia of Mathematics”</span></a> (<a href="#ref-bolza" role="doc-biblioref">n.d.</a>)</span>)
<span class="math display">\[\begin{gather*}
  \min_{u(t), t_0, t_f, x(t_0)} K(t_0, x(t_0), t_f, x(t_f)) + \int_{t_0}^{t_f} L(x(t), u(t), t) \\
  \text{s.t. } \dot{x}(t) = f(x(t), u(t), t),\ (t_0, x(t_0), t_f, x(t_f)) \in \mathcal{B},\ u(t) \in U.
\end{gather*}\]</span>
<span class="math inline">\(x\)</span> is commonly referred to as the state and <span class="math inline">\(u\)</span> the control.
<span class="math inline">\(f\)</span> encodes the dynamics of the state, <span class="math inline">\(K\)</span> is an initial/terminal cost and <span class="math inline">\(L\)</span> is the running cost.
The initial time and state and terminal time and state are constrained as they have to lie in <span class="math inline">\(\mathcal{B}\)</span> whilst the control lies in <span class="math inline">\(U\)</span>.</p>
<p>Pontryagin’s principle is a set of necessary conditions for an optimal solution to this problem.</p>
<p>The Bolza problem can easily be converted into one with <span class="math inline">\(L \equiv 0\)</span><a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>, a Mayer problem, or one with <span class="math inline">\(K \equiv 0\)</span>, a Lagrange problem (see <span class="citation"><a href="#ref-bolza" role="doc-biblioref"><span>“Bolza Problem - Encyclopedia of Mathematics”</span></a> (<a href="#ref-bolza" role="doc-biblioref">n.d.</a>)</span> or <span class="citation"><a href="#ref-lib2012" role="doc-biblioref">Liberzon</a> (<a href="#ref-lib2012" role="doc-biblioref">2012</a>)</span> on how to do this).
The time dependence in the dynamics and the cost can also be easily incorporated into the state by augmenting the state with a variable representing time.</p>
<p>This reformulated problem is stated as follows, where <span class="math inline">\(x\)</span> is the augmented state and <span class="math inline">\(L\)</span> the augmented cost
<span class="math display">\[\begin{gather*}
  \min \int_{t_0}^{t_f} L(x, u) \\
  \text{s.t. } \dot{x} = f(x, u),\ (x(t_0), x(t_f)) \in \mathcal{B},\ u \in U
\end{gather*}\]</span></p>
<p>Pontryagin’s principle for this problem is as follows, <span class="citation"><a href="#ref-ber2013" role="doc-biblioref">Berkovitz and Medhin</a> (<a href="#ref-ber2013" role="doc-biblioref">2013</a>)</span> (page 170). Let <span class="math inline">\(x(t), u(t), t_0, t_f\)</span> be the optimal solutions to the problem then:</p>
<ol style="list-style-type: lower-roman">
<li><p>There exists an absolutely continuous function <span class="math inline">\(\hat{\lambda}(t) = (\lambda_0, \lambda(t))\)</span> defined on <span class="math inline">\([t_0, t_f]\)</span> such that <span class="math inline">\(\lambda_0\)</span> is either <span class="math inline">\(-1\)</span> or <span class="math inline">\(0\)</span>, and <span class="math inline">\(\hat{\lambda} \neq \boldsymbol 0\)</span> for all <span class="math inline">\(t \in [t_0, t_f]\)</span>.
Then we can define the Hamiltonian, <span class="math inline">\(H\)</span>, to be <span class="math inline">\(H\left( x, u, \hat{\lambda} \right) = \lambda(t) \cdot f(x(t), u(t)) + \lambda_0 L(x, u)\)</span>.</p></li>
<li><p><span class="math display">\[\begin{gather*}
  \dot{\lambda}(t) = -\nabla_x H\left( x(t), u(t), \hat{\lambda}(t) \right)
\end{gather*}\]</span></p></li>
<li><p><span class="math display">\[\begin{gather*}
  H(x(t),\ u(t),\ \hat{\lambda}(t)) \geq H(x(t),\ w,\ \hat{\lambda}(t)) \hspace{0.3cm} \; \forall \; w \in U \hspace{0.3cm} \text{a.e. on } t \in [t_0, t_f]
\end{gather*}\]</span>
Simply put the Hamiltonian must be maximised with respect to <span class="math inline">\(u\)</span> at all times<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>.</p></li>
<li><p>The following <em>transversality condition</em> must be satisfied: Let <span class="math inline">\(\psi(t) = [x(t), u(t), \hat{\lambda}(t) ]\)</span>, then <span class="math inline">\([ H(\psi(t_0)),\ -\lambda(t_0),\ -H(\psi(t_f)),\ \lambda(t_f) ]\)</span> must be orthogonal to the tangent space to <span class="math inline">\(\mathcal{B}\)</span> at the point <span class="math inline">\([ t_0,\ x(t_0),\ t_f,\ x(t_f) ]\)</span><a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>.
It follows then if we can vary the initial time freely then <span class="math inline">\(H(\psi(t_0)) = 0\)</span> and similarly if we can vary the final time <span class="math inline">\(H(\psi(t_f)) = 0\)</span>.</p></li>
</ol>
<p>It is shown in <span class="citation"><a href="#ref-lib2012" role="doc-biblioref">Liberzon</a> (<a href="#ref-lib2012" role="doc-biblioref">2012</a>)</span> that the Hamiltonian is a constant with respect to time.</p>
<p>There are many different proofs for Pontryagin’s principle depending on if we have initial/ target sets and what assumptions we make, e.g. do we assume everything is differentiable or not?</p>
<p>An example where Pontryagin’s principle has been applied is the <a href="/post/gfold-2007">pin-point landing problem</a>.</p>
</div>
<div id="proofs" class="section level1">
<h1>Proofs</h1>
<p>I will outline some different proofs below.</p>
<div id="dynamic-programming" class="section level2">
<h2>Dynamic Programming</h2>
<p>There is the dynamic programming approach in <span class="citation"><a href="#ref-ber2017" role="doc-biblioref">Bertsekas</a> (<a href="#ref-ber2017" role="doc-biblioref">2017</a>)</span> or <span class="citation"><a href="#ref-lib2012" role="doc-biblioref">Liberzon</a> (<a href="#ref-lib2012" role="doc-biblioref">2012</a>)</span>.</p>
</div>
<div id="quick-proof" class="section level2">
<h2>Quick Proof</h2>
<p>Let’s say our problem is
<span class="math display">\[\begin{gather*}
  \min K(x(T)) \\
  \text{s.t. } \dot{x}(t) = f(x(t), u(t)), \ u(t) \in U
\end{gather*}\]</span> where I believe <span class="math inline">\(T\)</span> is either fixed or free.</p>
<p>If we have trajectories <span class="math inline">\((x_\epsilon, u_\epsilon)\)</span> which are a variation of the optimal trajectories <span class="math inline">\((x^*, u^*)\)</span> with <span class="math inline">\(\epsilon \geq 0\)</span> and <span class="math display">\[\begin{gather*}
  \lim_{\epsilon \to 0^+} (x_\epsilon, u_\epsilon) = (x^*, u^*) 
\end{gather*}\]</span><a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>
Now, we know a small increase in <span class="math inline">\(\epsilon\)</span> at <span class="math inline">\(\epsilon=0\)</span> must increase the objective function. Therefore
<span class="math display">\[\begin{gather*}
  0 \leq \left. \frac{\partial}{\partial \epsilon} \right|_{\epsilon=0^+} K(x_\epsilon(T)) = \nabla K(x^*(T)) \left. \frac{\partial}{\partial \epsilon} \right|_{\epsilon=0^+} x_\epsilon(T)
\end{gather*}\]</span>
Let <span class="math inline">\(\lambda(T) = - \nabla K(x^*(t))\)</span> and <span class="math inline">\(v(t) = \left. \frac{\partial}{\partial \epsilon} \right|_{\epsilon=0^+} x_\epsilon(t)\)</span>. So <span class="math inline">\(\lambda(T) v(T) \leq 0\)</span></p>
<p>We want to show <span class="math inline">\(\lambda(t)f(x^*, u^*) \geq \lambda(t)f(x^*, w)\)</span> for all <span class="math inline">\(w \in U\)</span> and <span class="math inline">\(t \in [0, T]\)</span>. If we construct <span class="math inline">\(v(t) = f(x^*, w) - f(x^*, u^*)\)</span> then we can see the statement is true when <span class="math inline">\(t = T\)</span>. Additionally if we can show <span class="math inline">\(\lambda(t)v(t)\)</span> has the same sign for all <span class="math inline">\(t \in [0, T]\)</span> then we see the desired results follows.</p>
<p>We consider control ``perturbations that may be large in magnitude by are confined to small time intervals. The net effect on the trajectory of such perturbations will then be small’’ <span class="citation"><a href="#ref-hoc1991" role="doc-biblioref">Hocking</a> (<a href="#ref-hoc1991" role="doc-biblioref">1991</a>)</span>.
It turns out we can use a type of variation called a needle variation which is defined as:
<span class="math display">\[\begin{align*}
  u_\epsilon(t) = \begin{cases}
    \omega &amp; \text{if } t \in [\tau - \epsilon, \tau] \\
    u^*(t) &amp; \text{else}
  \end{cases} 
\end{align*}\]</span>
where <span class="math inline">\(\tau \in (0, T]\)</span> and <span class="math inline">\(0 &lt; \tau - \epsilon &lt; \tau\)</span> and <span class="math inline">\(\omega \in U\)</span>.
Importantly it is possible to differentiate along a needle variation and they are simple <span class="citation"><a href="#ref-dmi2016" role="doc-biblioref">Dmitruk and Osmolovskii</a> (<a href="#ref-dmi2016" role="doc-biblioref">2016</a>)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:needle"></span>
<img src="Needle%20variation.png" alt="@aro123" width="50%" />
<p class="caption">
Figure 1: <span class="citation"><a href="#ref-aro123" role="doc-biblioref">M. S. Aronna</a> (<a href="#ref-aro123" role="doc-biblioref">2020</a>)</span>
</p>
</div>
<p>Let <span class="math inline">\(x_\epsilon(t)\)</span> be the corresponding response to our system:
<span class="math display">\[\begin{align*}
  \dot{x}_\epsilon(t) &amp;= f(x_\epsilon(t), u_\epsilon(t)) \\
  x_\epsilon(0) &amp;= x^*(0)
\end{align*}\]</span></p>
<p>We want to understand how our choices of <span class="math inline">\(\tau\)</span> and <span class="math inline">\(\omega\)</span> cause <span class="math inline">\(x_\epsilon(t)\)</span> to differ from <span class="math inline">\(x^*(t)\)</span> for small <span class="math inline">\(\epsilon &gt; 0\)</span>.</p>
<p>For <span class="math inline">\(t \geq \tau\)</span> both <span class="math inline">\(x^*(t)\)</span> and <span class="math inline">\(x_\epsilon(t)\)</span> follow <span class="math inline">\(u^*(t)\)</span> so they solve the same ODE but with differing initial conditions.</p>
<p>Clearly <span class="math inline">\(x_\epsilon(t) = x^*(t)\)</span> for <span class="math inline">\(0 \leq t \leq \tau - \epsilon\)</span> and <span class="math inline">\(x_\epsilon(\tau) = x^*(\tau) + \epsilon v(\tau) + o(\epsilon)\)</span><a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>. We also get <span class="math inline">\(v(\tau) = \left. \frac{\partial}{\partial \epsilon} \right|_{\epsilon=0^+} x_\epsilon(\tau) = f(x^*(\tau), \omega) - f(x^*(\tau), u^*(\tau))\)</span> from <span class="citation"><a href="#ref-lib2012" role="doc-biblioref">Liberzon</a> (<a href="#ref-lib2012" role="doc-biblioref">2012</a>)</span> or <span class="citation"><a href="#ref-aro123" role="doc-biblioref">M. S. Aronna</a> (<a href="#ref-aro123" role="doc-biblioref">2020</a>)</span>.</p>
<p>Also,
<span class="math display">\[\begin{align*}
  \dot{x}_\epsilon(t) &amp;= \dot{x}^*(t) + \epsilon \dot{v}(t) \ \ \text{ for } t \geq \tau \\
  \dot{x}_\epsilon(t) &amp;= f(x_\epsilon(t), u^*(t)) \text{ for } t \geq \tau  \\
  &amp;= f(x^*(t) + \epsilon v(t) + o(\epsilon), u^*(t)) \\
  &amp;\approx f(x^*(t), u^*(t)) + \epsilon v(t) \nabla_x f(x^*(t), u^*(t)) \\
  &amp;= \dot{x}^*(t) + \epsilon v(t) \nabla_x f(x^*(t), u^*(t)) \\
  \therefore \dot{v}(t) &amp;= v(t) \nabla_x f(x^*(t), u^*(t))
\end{align*}\]</span></p>
<p>We let <span class="math inline">\(v(t) = 0\)</span> for <span class="math inline">\(0 \leq t &lt; \tau\)</span>, <span class="math inline">\(v(t)\)</span> represents the difference between <span class="math inline">\(x_\epsilon\)</span> and <span class="math inline">\(x^*\)</span> after the needle perturbation stops acting.</p>
<p>We can construct <span class="math inline">\(\lambda(t)\)</span> so that <span class="math inline">\(\lambda(t)v(t)\)</span> has the same sign for all <span class="math inline">\(t \in [0, T]\)</span> by setting <span class="math inline">\(\frac{d }{d t} \lambda(t)v(t) = 0\)</span>.
<span class="math display">\[\begin{align*}
  \lambda(t) \dot{v}(t) + \dot{\lambda}(t) v(t) &amp;= \lambda(t) v(t) \nabla_x f(x^*(t), u^*(t)) + \dot{\lambda}(t) v(t) = 0 \\ 
  \implies \dot{\lambda}(t) &amp;= - \lambda(t) \nabla_x f(x^*(t), u^*(t))  \\
  &amp;= - \nabla_x H, \quad \text{$H = \lambda(t) \cdot f(x(t), u(t))$ as $L \equiv 0$}
\end{align*}\]</span></p>
<p>So now we know <span class="math inline">\(\lambda(t)v(t) \leq 0\)</span> for all <span class="math inline">\(t\)</span>.
Now to finish the proof we can note that <span class="math inline">\(v(\tau) = f(x^*(\tau), \omega) - f(x^*(\tau), u^*(\tau))\)</span> a.e. on <span class="math inline">\(\tau \in (0, T)\)</span> for all <span class="math inline">\(\omega \in U\)</span> and <span class="math inline">\(\lambda(\tau) v(\tau) = \lambda(T) v(T) \leq 0\)</span>.
So <span class="math inline">\(\lambda(\tau) f(x^*(\tau), \omega) \leq \lambda(t) f(x^*(\tau), u^*(\tau))\)</span> a.e. on <span class="math inline">\(\tau \in (0, T)\)</span> for all <span class="math inline">\(\omega \in U\)</span> completing the proof</p>
<p>You may want to look at A.2 and A.3 in <span class="citation"><a href="#ref-evans" role="doc-biblioref"><span>“An Introduction to Mathematical Optimal Control Theory”</span></a> (<a href="#ref-evans" role="doc-biblioref">n.d.</a>)</span>, <span class="citation"><a href="#ref-aro23" role="doc-biblioref">S. Aronna</a> (<a href="#ref-aro23" role="doc-biblioref">2013</a>)</span>, <span class="citation"><a href="#ref-aro123" role="doc-biblioref">M. S. Aronna</a> (<a href="#ref-aro123" role="doc-biblioref">2020</a>)</span> and 4.2.3 and 4.2.4 from <span class="citation"><a href="#ref-lib2012" role="doc-biblioref">Liberzon</a> (<a href="#ref-lib2012" role="doc-biblioref">2012</a>)</span> for further details.</p>
</div>
<div id="original-proof" class="section level2">
<h2>Original Proof</h2>
<p>The book, <span class="citation"><a href="#ref-lib2012" role="doc-biblioref">Liberzon</a> (<a href="#ref-lib2012" role="doc-biblioref">2012</a>)</span>, has a good summary of this proof and explains the proof nicely as well.
I quite like this proof as it gives a clear geometric intuition.</p>
<p>Here are the <a href="Pontryagin’s%20principle.pptx">slides</a> for a talk I gave summarising this proof.</p>
</div>
</div>
<div id="role-of-abnormal-multiplier-lambda_0" class="section level1">
<h1>Role of abnormal multiplier <span class="math inline">\(\lambda_0\)</span></h1>
<p>I haven’t been able to fully work out when <span class="math inline">\(\lambda_0 = 0\)</span> (it may be an open problem) so below I list some results concerning <span class="math inline">\(\lambda_0\)</span>.</p>
<!-- When $\lambda_0$ = 0 we have an abnormal problem, implying the system is not controllable/ the normality condition is not satisfied/ fixed time, but non fixed final state will never be abnormal? !-->
<p>For linear control systems all trajectories for uncontrollable systems are possibly abnormal extremals (i.e. <span class="math inline">\(\lambda_0\)</span> can be <span class="math inline">\(0\)</span> but it doesn’t have to be <span class="math inline">\(0\)</span>) <span class="citation"><a href="#ref-lewis" role="doc-biblioref"><span>“The Maximum Principle of Pontryagin in Control and in Optimal Control”</span></a> (<a href="#ref-lewis" role="doc-biblioref">n.d.</a>)</span>.</p>
<p>In the original proof we have a separating hyperplane and <span class="math inline">\(\lambda_0 = 0 \iff\)</span><a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> the separating hyperplane is vertical.</p>
<p>Claim: <span class="math inline">\((-1, 0, \dots, 0)\)</span> lies on the boundary of the tangent cone <span class="math inline">\(\iff \lambda_0\)</span> has to be <span class="math inline">\(0\)</span><a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a>, i.e. <span class="math inline">\(\lambda_0 = -1\)</span> doesn’t generate any valid solutions.</p>
<div class="proof">
<p><span id="unlabeled-div-1" class="proof"><em>Proof</em>. </span>The tangent cone is <span class="math inline">\(C_{t^*}\)</span>, consider if <span class="math inline">\(\mu = (-1, 0, \dots, 0)\)</span> lied on its boundary then the separating hyperplane would have to contain <span class="math inline">\(\mu\)</span> and so would be vertical as it also contains <span class="math inline">\(y^*\)</span> (the optimal state what we have been calling <span class="math inline">\(x^*\)</span>) by the definition of the separating hyperplane.</p>
<p>Conversely, if <span class="math inline">\(\lambda_0\)</span> has to be <span class="math inline">\(0\)</span> then if the separating hyperplane wasn’t vertical it would not be able to separate <span class="math inline">\(\mu\)</span> and the tangent cone so <span class="math inline">\(\mu\)</span> must lie on the boundary of the tangent cone<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:boundary"></span>
<img src="boundary.png" alt="@lib2012" width="50%" />
<p class="caption">
Figure 2: <span class="citation"><a href="#ref-lib2012" role="doc-biblioref">Liberzon</a> (<a href="#ref-lib2012" role="doc-biblioref">2012</a>)</span>
</p>
</div>
</div>
<p>Claim: If an optimal trajectory is not tangent to <span class="math inline">\(S_1\)</span> then <span class="math inline">\(\lambda_0 \neq 0\)</span>, <span class="citation"><a href="#ref-ber2013" role="doc-biblioref">Berkovitz and Medhin</a> (<a href="#ref-ber2013" role="doc-biblioref">2013</a>)</span> (page 172), where <span class="math inline">\(S_1\)</span> is the set of values the final state has to lie in.</p>
<div class="proof">
<p><span id="unlabeled-div-2" class="proof"><em>Proof</em>. </span>Consider the tangent space to <span class="math inline">\(S_1\)</span> and the line formed by variations to the final time, both must lie in the separating hyperplane.
The line formed by variations to the final time will be tangent to trajectory at optimal final time as the line is in the direction of the gradient of <span class="math inline">\(f\)</span> at final time.
So if an optimal trajectory is not tangent to <span class="math inline">\(S_1\)</span> then <span class="math inline">\(S_1\)</span> is not tangent to the line formed by variations to the final time.
Then the separating hyperplane cannot be vertical otherwise it will intersect the tangent cone or the tangent space to <span class="math inline">\(S_1\)</span> and so will not be separating.
Therefore <span class="math inline">\(\lambda_0 = -1\)</span> as <span class="math inline">\(\lambda_0 = 0\)</span> iff the separating hyperplane is vertical.</p>
</div>
<p>Unfortunately the converse is not true, if an optimal trajectory is tangent to <span class="math inline">\(S_1\)</span> then <span class="math inline">\(\lambda_0\)</span> can be <span class="math inline">\(0\)</span> or <span class="math inline">\(-1\)</span><a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a>.</p>
<div class="proof">
<span id="unlabeled-div-3" class="proof"><em>Proof</em>. </span>Suppose the statement is false.
Consider the system in the diagram below, but where the <span class="math inline">\(T\)</span> is tangent to the optimal trajectory, i.e. it is parallel to <span class="math inline">\(C^t\)</span>/ lies on the thick line.
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:tangent"></span>
<img src="tangent.png" alt="@lib2012" width="75%" />
<p class="caption">
Figure 3: <span class="citation"><a href="#ref-lib2012" role="doc-biblioref">Liberzon</a> (<a href="#ref-lib2012" role="doc-biblioref">2012</a>)</span>
</p>
</div>
<p>Clearly <span class="math inline">\(\lambda_0 \neq 0\)</span> in this example so we have a contradiction.</p>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-evans" class="csl-entry">
<span>“An Introduction to Mathematical Optimal Control Theory.”</span> n.d. Accessed September 20, 2021. <a href="https://math.berkeley.edu/~evans/control.course.pdf">https://math.berkeley.edu/~evans/control.course.pdf</a>.
</div>
<div id="ref-aro123" class="csl-entry">
Aronna, María Soledad. 2020. <span>“On the Pontryagin Maximum Principle,”</span> October, 123. <a href="http://utrechtgeometrycentre.nl/wp-content/uploads/2020/12/Aronna-Complete-notes.pdf">http://utrechtgeometrycentre.nl/wp-content/uploads/2020/12/Aronna-Complete-notes.pdf</a>.
</div>
<div id="ref-aro23" class="csl-entry">
Aronna, Soledad. 2013. <span>“Lecture on the Pontryagin Maximum Principle,”</span> January, 23. <a href="http://itn-sadco.inria.fr/itn-sadco.inria.fr/files/yrw-2013/YRW2013-Aronna.pdf/at_download/YRW2013-Aronna.pdf">http://itn-sadco.inria.fr/itn-sadco.inria.fr/files/yrw-2013/YRW2013-Aronna.pdf/at_download/YRW2013-Aronna.pdf</a>.
</div>
<div id="ref-ber2013" class="csl-entry">
Berkovitz, Leonard David, and Negash G. Medhin. 2013. <span>“Nonlinear Optimal Control Theory.”</span> In, 170. CRC Press.
</div>
<div id="ref-ber2017" class="csl-entry">
Bertsekas, Dimitri P. 2017. <em>Dynamic Programming and Optimal Control: 1</em>. 4th edition. Nashua, <span>NH</span>: Athena Scientific.
</div>
<div id="ref-bolza" class="csl-entry">
<span>“Bolza Problem - Encyclopedia of Mathematics.”</span> n.d. Accessed September 20, 2021. <a href="https://encyclopediaofmath.org/wiki/Bolza_problem">https://encyclopediaofmath.org/wiki/Bolza_problem</a>.
</div>
<div id="ref-dmi2016" class="csl-entry">
Dmitruk, Andrei, and Nikolai Osmolovskii. 2016. <span>“On the Proof of Pontryagin?s Maximum Principle by Means of Needle Variations.”</span> <em>Fundamental and Applied Mathematics</em> 19 (November). <a href="https://doi.org/10.1007/s10958-016-3044-2">https://doi.org/10.1007/s10958-016-3044-2</a>.
</div>
<div id="ref-hoc1991" class="csl-entry">
Hocking, L. M. 1991. <em>Optimal Control: An Introduction to the Theory with Applications</em>. Oxford Applied Mathematics and Computing Science Series. Clarendon Press. <a href="https://books.google.co.uk/books?id=gd7b4FMqXpMC">https://books.google.co.uk/books?id=gd7b4FMqXpMC</a>.
</div>
<div id="ref-lib2012" class="csl-entry">
Liberzon, Daniel. 2012. <em>Calculus of Variations and Optimal Control Theory</em>. <a href="https://press.princeton.edu/books/hardcover/9780691151878/calculus-of-variations-and-optimal-control-theory">https://press.princeton.edu/books/hardcover/9780691151878/calculus-of-variations-and-optimal-control-theory</a>.
</div>
<div id="ref-lewis" class="csl-entry">
<span>“The Maximum Principle of Pontryagin in Control and in Optimal Control.”</span> n.d. Accessed September 20, 2021. <a href="https://mast.queensu.ca/~andrew/teaching/pdf/maximum-principle.pdf">https://mast.queensu.ca/~andrew/teaching/pdf/maximum-principle.pdf</a>.
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>i.e. <span class="math inline">\(L = 0\)</span> always<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>a.e. means all most everywhere, we can take this to be equivalent to for all for our purposes. What it actually means is that the condition may not hold for a set of values that is of measure <span class="math inline">\(0\)</span>, e.g. for a a finite set of values<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>I.e. <span class="math inline">\([ H(\psi(t_0)),\ -\lambda(t_0),\ -H(\psi(t_f)),\ \lambda(t_f)] \cdot d = 0 \quad \forall \; d \in T_{[ t_0,\ x(t_0),\ t_f,\ x(t_f) ]} \mathcal{B}\)</span><a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>The trajectories approach the optimal trajectories as we decrease <span class="math inline">\(\epsilon\)</span><a href="#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>For any function with a derivative at <span class="math inline">\(t\)</span> we know <span class="math inline">\(x(t + h) = x(t) = h x&#39;(t) + o(h)\)</span><a href="#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p><span class="math inline">\(\iff\)</span> - iff, stands for if and only if,<span class="math inline">\(A \iff B\)</span> is equivalent ti <span class="math inline">\(A \implies B\)</span> and <span class="math inline">\(B \implies A\)</span> both being true<a href="#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>It is possible for <span class="math inline">\(\lambda_0\)</span> to be either <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span> for some problems.<a href="#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p><span class="math inline">\(\mu\)</span> can’t lie in the tangent cone as that would violate the optimality of <span class="math inline">\(y^*\)</span><a href="#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>Note <span class="math inline">\(A \implies B\)</span> is equivalent to <span class="math inline">\((\lnot B) \implies (\lnot A)\)</span> where <span class="math inline">\(\lnot A\)</span> is ‘not <span class="math inline">\(A\)</span>.’ The converse is <span class="math inline">\(B \implies A\)</span> or <span class="math inline">\((\lnot A) \implies (\lnot B)\)</span>.<a href="#fnref9" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
